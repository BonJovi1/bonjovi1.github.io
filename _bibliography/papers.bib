---
---

@string{aps = {American Physical Society,}}

@article{DeepMPCVS,
  title={DeepMPCVS: Deep Model Predictive Control For Visual Servoing},
  author={Pushkal Katara, Y V S Harish, Harit Pandya, Abhinav Gupta, AadilMehdi Sanchawala, Gourav Kumar, Brojeshwar Bhowmick and K. Madhava Krishna},
  abstract={The simplicity of the visual servoing approach makes it an attractive option for tasks dealing with vision-based control of robots in many real-world applications. However, attaining precise alignment for unseen environments pose a challenge to existing visual servoing approaches. While classical approaches assume a perfect world, the recent data-driven approaches face issues when gen- eralizing to novel environments. In this paper, we aim to combine the best of both worlds. We present a deep model predictive visual servoing framework that can achieve precise alignment with optimal trajectories and can generalize to novel environments. Our framework consists of a deep network for optical flow pre- dictions, which are used along with a predictive model to forecast future optical flow. For generating an optimal set of velocities we present a control network that can be trained on-the-fly without any supervision. Through extensive simulations on photo-realistic indoor settings of the popular Habitat framework, we show sig- nificant performance gain due to the proposed formulation vis-a-vis recent state of the art methods. Specifically, we show a faster convergence and an improved performance in trajectory length over recent approaches.},
  journal={4th Conference on Robot Learning (CoRL)},
  year={2020},
  month={November},
  url={https://robotics.iiit.ac.in/publications/2020/deep-mpc-for-visual-servoing/project-page.html},
  html={https://robotics.iiit.ac.in/publications/2020/deep-mpc-for-visual-servoing/project-page.html},
  pdf={DeepMPCVS.pdf}
}

@article{RTVS,
  title={RTVS: A Lightweight Differentiable MPC Framework for Real-Time Visual Servoing},
  author={Mohammad Nomaan Qureshi, Pushkal Katara, Abhinav Gupta, Harit Pandya, Y V S Harish, AadilMehdi Sanchawala, Gourav Kumar, Brojeshwar Bhowmick and K. Madhava Krishna},
  abstract={Recent data-driven approaches to visual servoing have shown improved performances over classical methods due to precise feature matching and depth estimation. Some recent servoing approaches use a model predictive control (MPC) framework which generalise well to novel environments and are capable of incorporating dynamic constraints, but are computationally intractable in real-time, making it difficult to deploy in real-world scenarios. On the contrary, singlestep methods optimise greedily and achieve high servoing rates, but lack the benefits of the MPC multi-step ahead formulation. In this paper, we make the best of both worlds and propose a lightweight visual servoing MPC framework which generates optimal control near real-time at a frequency of 10.52 Hz. This work utilises the differential cross-entropy sampling method for quick and effective control generation along with a lightweight neural network, significantly improving the servoing frequency. We also propose a novel flow normalisation layer which ameliorates the issue of inferior predictions from the flow network. We conduct extensive experimentation on the Habitat simulator and show a notable decrease in servoing time in comparison with other approaches that optimise over a time horizon. We achieve the right balance between time and performance for visual servoing in six degrees of freedom (6DoF), while retaining the advantageous MPC formulation.},
  journal={IEEE International Conference on Intelligent Robots and Systems},
  year={2021},
  month={July},
  pdf={RTVS.pdf}
}
